{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проводим работу с табличными данными, в которых представлена информация о стартапах, которые функционировали в период с 1980 по 2018 годы. Нужно предсказать, какие из них закроются, а какие нет. Соревнование проводится на популярной платформе Kaggle, что позволит не только применять на практике свои знания в области анализа данных и машинного обучения, но и освоить работу с этой платформой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цель исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Разработать модель машинного обучения для предсказания продолжения деятельности стартапа. \n",
    "- Провести полноценный разведочный анализ и сформировать рекомендации будущим создателям стартапов (какие факторы влияют на успешность стартапа)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этапы исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- загрузка и ознакомление с данными,\n",
    "- предварительная обработка,\n",
    "- полноценный разведочный анализ,\n",
    "- разработка новых синтетических признаков,\n",
    "- проверка на мультиколлинеарность,\n",
    "- отбор финального набора обучающих признаков,\n",
    "- выбор и обучение моделей,\n",
    "- итоговая оценка качества предсказания лучшей модели,\n",
    "- анализ важности ее признаков,\n",
    "- подготовка отчета по исследованию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из двух файлов: \n",
    "- тренировочный набор (около 53к записей) и тестовый набор (около 13к записей). \n",
    "- Тренировочный набор содержит целевой признак status, указывающий на то, закрылся стартап или продолжает действовать. \n",
    "Временной период - '1970-01-01' по '2018-01-01'. \n",
    "Дата формирования выгрузки - '2018-01-01'\n",
    "\n",
    "- `kaggle_startups_train_27042024.csv` - информация (53 000) стартапах, которые будут использоваться в качестве обучающих данных.\n",
    "- `kaggle_startups_test_27042024.csv` - информация (13 000) стартапах, которые будут использоваться в качестве тестовых данных. Ваша задача - предсказать значение 'status' для каждого стартапа из этого датасета.\n",
    "- `kaggle_startups_sample_submit_27042024.csv` - файл с примером предсказаний в правильном формате.\n",
    "name - идентификатор (название) стартапа в тестовом наборе.\n",
    "status - целевой признак. Для каждого стартапа предскажите категориальное значение соответствующее прогнозу ['operating', 'closed']. \n",
    "\n",
    "**Описание полей данных**\n",
    "- `name` - Название стартапа\n",
    "- `category_list` - Список категорий, к которым относится стартап\n",
    "- `funding_total_usd` - Общая сумма финансирования в USD\n",
    "- `status` - Статус стартапа (закрыт или действующий)\n",
    "- `country_code` - Код страны\n",
    "- `state_code` - Код штата\n",
    "- `region` - Регион\n",
    "- `city` - Город\n",
    "- `funding_rounds` - Количество раундов финансирования\n",
    "- `founded_at` - Дата основания\n",
    "- `first_funding_at` - Дата первого раунда финансирования\n",
    "- `last_funding_at` - Дата последнего раунда финансирования\n",
    "- `closed_at` - Дата закрытия стартапа (если применимо)\n",
    "- `lifetime` - Время существования стартапа в днях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install phik -q\n",
    "! pip install shap -q\n",
    "! pip install -U scikit-learn -q\n",
    "! pip install seaborn --upgrade -q\n",
    "! pip install missingno -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import phik  # noqa: F401\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.float_format\", \"{:.3f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    print(\"Изучение данных датафрейма\")\n",
    "    print(\"Вывод первых 5 строк \\n\")\n",
    "    display(df.head(5))\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Размерность датафрейма, составляет - {(df.shape)}\")\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Общая информация:\\n\")\n",
    "    display(df.info())\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Описательная статистика:\\n\")\n",
    "    display(df.describe())\n",
    "    print(\"-\" * 100)\n",
    "    df.isna().sum()\n",
    "    print(\"Проверка на наличие явных дубликатов:\\n\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Вывод количества уникальных значений\")\n",
    "    display(pd.DataFrame(df.apply(lambda x: x.nunique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = \"./datasets/kaggle_startups_train_27042024.csv\"\n",
    "pth2 = \"./datasets/kaggle_startups_test_27042024.csv\"\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    # Тренировочная выборка:\n",
    "    df_ks_train = pd.read_csv(\n",
    "        pth1,\n",
    "        parse_dates=[\"founded_at\", \"first_funding_at\", \"last_funding_at\", \"closed_at\"],\n",
    "    )\n",
    "    if os.path.exists(pth2):\n",
    "        # Тестовая выборка:\n",
    "        df_ks_test = pd.read_csv(\n",
    "            pth2, parse_dates=[\"founded_at\", \"first_funding_at\", \"last_funding_at\"]\n",
    "        )\n",
    "    else:\n",
    "        print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и ознакомление с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем первоначальную информацию о датафрейме с тренировочными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(df_ks_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим количество пропусков в тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df_ks_train.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта осей\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "# Генерация графика с использованием объекта осей\n",
    "msno.matrix(df_ks_train, ax=ax, sparkline=False)\n",
    "# Добавление названия графика\n",
    "ax.set_title(\"Матрица пропущенных значений\")\n",
    "# Отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что можно сказать из первоначальных данных:**\n",
    "- `name` - имеет 1 пропуск, удалим так как он не испорит общую картину\n",
    "- `category_list`   - список категорий -  имеет большое количество пропусков, подумаем что с ними можно сделать - 2465, возможно просто внесем категорию Unknown, так же иммет огромное количество категорий, но множество из них разделено знаком |, предлагаю удалить данные после данного символа и оставить название категории до вышеуказанного символа. Позволит уменьшить количество уникальных категорий.\n",
    "- `funding_total_usd`   - Общая сумма финансирования в USD - тоже множество пропусков  - 10069, предлагаю заполнить медианными значениями по группе категория стартапа. Не имеющие данных либо категорию неизвестно - заполнить глобальным медианным значением.\n",
    "- `status`   - статус. Не имеет проблем в данных. Это наш целевой признак.\n",
    "- `country_code`     - код старны - имеет много пропусков 5501, чем заполнить пока не ясно, оставим, так же имеет не так много категорий, переведем в категориальный тип. Предлагаю заполнить категорией Unknown, а те коды группа которых составляет меньше 10 - сделать как - Other.\n",
    "- `state_code`      state_code - Код штата    имеет много пропусков  6762, чем заполнить пока не ясно, оставим, так же имеет не большое количество категорий, переведем в категориальный тип. Думаю данная колонка не нужна нам для обучения модели, так как согласно матрице пропусков, это все географические названия и пропуски связаны между собой. Для обучения будем использовать код страны.\n",
    "- `region`        - региона, много пропусков -  6358, и много категорий. Думаю дальше данные эти не понадобятся для обучения модели, оставим пропуски. Думаю данная колонка не нужна нам для обучения модели, так как согласно матрице пропусков, это все географические названия и пропуски связаны между собой. Для обучения будем использовать код страны\n",
    "- `city`           - город, много пропусков -        6358, соответствует данным по региону. Вообще все пропуски связанные с географическим положением не заполнены в одинх и теж же строках, это можно наглядно увидеть по матрице пропусков. Возможно кто то заполнял только код страны, а остальные данные были не обязательны для заполнения, либо данные о них просто отсутствовали. Думаю данная колонка не нужна нам для обучения модели, так как согласно матрице пропусков, это все географические названия и пропуски связаны между собой. Для обучения будем использовать код страны \n",
    "- `funding_rounds`  -   Количество раундов финансирования    - Не имеет проблем в данных. Только переведем в int, так как даные числовые.\n",
    "- `founded_at`       -    Дата основания    - Не имеет проблем в данных.\n",
    "- `first_funding_at`  -     Дата первого раунда финансирования - Не имеет проблем в данных.\n",
    "- `last_funding_at`    -      Дата последнего раунда финансирования - Не имеет проблем в данных.\n",
    "- `closed_at`        -    Дата закрытия стартапа (если применимо) - имеет большое количество пропусков - 47599, что может говорит о том, что большинство из представленных в данных стартапов являются действующими. Данная колонка будет мешать предсказанию, так как нам надо именно предсказать будет ли закрыт стартап или нет, и оставив ее мы получим утечку целевого признака, поэтому заполним пропуски датой выгрузки данных и создадим новую синтетическую информацию, а именно `lifetime` - Время существования стартапа в днях, для этого посчитаем количество дней прошедших между датой основания и датой закрытия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительная обработка даных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведение типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train = df_ks_train.astype(\n",
    "    {\"funding_rounds\": np.int32, \"funding_total_usd\": np.float32}\n",
    ")\n",
    "df_ks_train[df_ks_train.select_dtypes([\"object\"]).columns] = df_ks_train.select_dtypes(\n",
    "    [\"object\"]\n",
    ").apply(lambda x: x.astype(\"category\"))\n",
    "df_ks_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с пропусками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с пропусками в колонке name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_name_row = df_ks_train[df_ks_train[\"name\"].isna()]\n",
    "missing_name_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим ее и сбросим индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train = df_ks_train.dropna(subset=[\"name\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим на пропуски\n",
    "df_ks_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с колонкой category_list**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной колонке очень много уникальных значений, но почти все они имеют разделитиель в качестве знака | , укрупним группы, оставив только первое наименование категории как самое крупное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем .loc[] для обновления столбца 'category_list'\n",
    "df_ks_train.loc[:, \"category_list\"] = df_ks_train[\"category_list\"].str.split(\"|\").str[0]\n",
    "# Подсчитываем количество уникальных категорий\n",
    "unique_categories = df_ks_train[\"category_list\"].nunique()\n",
    "# Выводим количество уникальных категорий\n",
    "unique_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас существенно уменьшилось количество категорий к которым относятся стартапы с 22108 до 707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим пропуски в данной категории заглушкой \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"category_list\"] = df_ks_train[\"category_list\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество уникальных значений в каждой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = df_ks_train[\"category_list\"].value_counts()\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что некоторые категории содержат по 1 включению, это помешает обучать модель, да и в принципе такие данные не информативны, заменим такие категории на Other. Порогом будет менее 5 включений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"category_list\"] = df_ks_train[\"category_list\"].apply(\n",
    "    lambda x: \"Other\" if category_counts[x] < 5 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"category_list\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смогли уменьшить количество категорий до 478, считаю это вполне успешным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Построим график ТОП 10 категорий стартапов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем фильтрованный датафрейм без категории 'Unknown'\n",
    "filtered_df = df_ks_train[df_ks_train[\"category_list\"] != \"Unknown\"]\n",
    "\n",
    "# Подсчитываем количество проектов по категориям, исключая 'Unknown'\n",
    "category_counts = filtered_df[\"category_list\"].value_counts().head(10)\n",
    "\n",
    "# Строим график топ-10 категорий по количеству проектов\n",
    "category_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Топ-10 категорий по количеству проектов\")\n",
    "plt.xlabel(\"Категории\")\n",
    "plt.ylabel(\"Количество проектов\")\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смогли снизить количество категорий, а так же визуализировали наиболее часто встречающиеся стартапы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с колонкой status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим на пропуски\n",
    "df_ks_train.status.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = df_ks_train.status.value_counts()\n",
    "plt.bar(\n",
    "    category_counts.index, category_counts.values, color=\"skyblue\", edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "# Добавляем название диаграммы и осей\n",
    "plt.title(\"Текущий статус стартапа\")\n",
    "plt.xlabel(\"Статус\")\n",
    "plt.ylabel(\"Количество\")\n",
    "\n",
    "# Отображаем график\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенных значений нет, большинство стартапов являются действующими"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с колонкой country_code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories_country_code = df_ks_train[\"country_code\"].nunique()\n",
    "unique_categories_country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var = df_ks_train[\"country_code\"].unique()\n",
    "new_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим пропуски на заглушку 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем 'Unknown' в категории\n",
    "df_ks_train[\"country_code\"] = df_ks_train[\"country_code\"].cat.add_categories(\n",
    "    [\"Unknown\"]\n",
    ")\n",
    "\n",
    "# Заменяем NaN на 'Unknown'\n",
    "df_ks_train[\"country_code\"] = df_ks_train[\"country_code\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество уникальных значений в каждой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_ks_train[\"country_code\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова видим много стран имеющих только по 1 включению, используем тот же подход и заменим на Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"country_code\"] = df_ks_train[\"country_code\"].apply(\n",
    "    lambda x: \"Other\" if counts[x] < 2 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"country_code\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график ТОП-10 Кодов стран, без учета \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем DataFrame, чтобы исключить строки с 'Unknown'\n",
    "filtered_df = df_ks_train[df_ks_train[\"country_code\"] != \"Unknown\"]\n",
    "# Подсчитываем количество проектов по странам, исключая 'Unknown'\n",
    "country_counts = filtered_df[\"country_code\"].value_counts().head(10)\n",
    "# Строим график топ-10 стран по количеству проектов\n",
    "country_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"топ-10 стран по количеству проектов\")\n",
    "plt.xlabel(\"Страны\")\n",
    "plt.ylabel(\"Количество проектов\")\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снизили количество категорий с 134 до 114 (возможно стоит взять порог побольше, но пока посмотрим так)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с колонкой state_code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories_state_code = df_ks_train[\"state_code\"].nunique()\n",
    "unique_categories_state_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"state_code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем множество уникальных значений, где есть и цифры и буквы и их комбинации. Попробуем уменьшить их количество объединив наиболее мелкие категории содержащие до 10 значений в одну категорию Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_ks_train[\"state_code\"].value_counts()\n",
    "threshold = 10  # Порог\n",
    "df_ks_train[\"state_code\"] = df_ks_train[\"state_code\"].apply(\n",
    "    lambda x: \"Other\" if counts[x] < threshold else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"state_code\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили существенное уменьшение категорий, заполним пропуски значением Unknown. Полагаю что данная колонка не понадобится  нам для обучения, поэтому можно просто поставить заглушку чтоб сохранить данные в других столбцах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем DataFrame, чтобы исключить строки с 'Unknown' и 'Other'\n",
    "filtered_df_2 = df_ks_train[\n",
    "    (df_ks_train[\"state_code\"] != \"Other\") & (df_ks_train[\"state_code\"] != \"Unknown\")\n",
    "]\n",
    "# Подсчитываем количество проектов по странам, исключая 'Unknown' и 'Other'\n",
    "state_counts = filtered_df_2[\"state_code\"].value_counts().head(10)\n",
    "# Строим график топ-10 по количеству проектов\n",
    "state_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"топ-10 кодов штата по количеству проектов\")\n",
    "plt.xlabel(\"Коды штатов\")\n",
    "plt.ylabel(\"Количество проектов\")\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открытые источники говорят что код штата СА - Калифорния, NY - Нью-Йорк, а МА - Массачусетс\n",
    "В принципе ТОП 3 кодов штатов, подтверждает предыдущий график, что больше всего стартапов в США, и уже внутри США самым оживленным по стартапам является Калифорния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Поработаем с колонкой funding_total_usd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"funding_total_usd\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим явный выброс, как значение 30 079 502 336, при том что медиана у нас всего 2 000 000 долларов, посмотрим на это значение и предлагаю удалить его. Так же предлагаю посмотреть значения которые выпадают за 99 квантиль и тоже удалить их, так как это будет не более 1% от выборки, а данные существенно улучшатся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление 99-го квантиля для столбца 'funding_total_usd'\n",
    "quantile_99 = df_ks_train[\"funding_total_usd\"].quantile(0.99)\n",
    "print(\n",
    "    f' значения выше чем {quantile_99} выпадают за 99 квантиль их количество составляет {len(df_ks_train.loc[df_ks_train[\"funding_total_usd\"] > quantile_99])}'\n",
    ")\n",
    "# Создание боксплота с ограничением данных 99-м квантилем\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.boxplot(\n",
    "    x=\"funding_total_usd\",\n",
    "    data=df_ks_train[df_ks_train[\"funding_total_usd\"] <= quantile_99],\n",
    "    orient=\"h\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.ticklabel_format(style=\"plain\", axis=\"x\")\n",
    "ax.set_title(\"Боксплот\")\n",
    "ax.set_xlabel(\"Общая сумма финансирования в USD (ограничено 99 квантилем)\")\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train = df_ks_train[\n",
    "    (df_ks_train[\"funding_total_usd\"] <= quantile_99)\n",
    "    | (df_ks_train[\"funding_total_usd\"].isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления значений выпадающих за 99 квантиль заполним оставщиеся значения по следующему принципу.\n",
    "Заполним пропущенные данные медианой по группе категорий.  Так как мы не знаем в какие категории могли попасть в 'Unknown', то заполним ее не медианой по группе 'Unknown', а глобальной медианой, для этого:\n",
    "Создадим функцию fill_with_median которая проверяет, равна ли категория - 'Unknown', и если это так, то она заполняет пропущенные значения в funding_total_usd глобальной медианой. Это гарантирует, что для категории 'Unknown' всегда будет использоваться глобальная медиана, а не медиана по группе 'Unknown'. Для остальных значений сначала проверяет есть ли в группе хоть 1 значение, если есть заполняет медианой по группе, в противном случае глобальной медианой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление глобальной медианы для столбца 'funding_total_usd'\n",
    "global_median = df_ks_train[\"funding_total_usd\"].median()\n",
    "\n",
    "\n",
    "def fill_with_median(group, category):\n",
    "    # Если категория группы - 'Unknown', заполнение NaN значений глобальной медианой\n",
    "    if category == \"Unknown\":\n",
    "        return group.fillna(global_median)\n",
    "    # Проверка наличия хотя бы одного не-NaN значения в группе\n",
    "    elif group.notna().any():\n",
    "        # Заполнение NaN значений медианой группы\n",
    "        return group.fillna(group.median())\n",
    "    else:\n",
    "        # Заполнение NaN значений глобальной медианой\n",
    "        return group.fillna(global_median)\n",
    "\n",
    "\n",
    "# Применение функции fill_with_median к каждой группе в столбце 'category_list'\n",
    "df_ks_train[\"funding_total_usd\"] = df_ks_train.groupby(\"category_list\")[\n",
    "    \"funding_total_usd\"\n",
    "].transform(lambda x: fill_with_median(x, x.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разработка новых синтетических признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание признака lifetime - Время существования стартапа в днях**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним closed_at датой выгрузки данных, для последующего создания столбца lifetime - Время существования стартапа в днях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"closed_at\"] = df_ks_train[\"closed_at\"].fillna(datetime(2018, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"lifetime\"] = (df_ks_train[\"closed_at\"] - df_ks_train[\"founded_at\"]).dt.days\n",
    "df_ks_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "closed_at\tнам больше не нужен, удалим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train = df_ks_train.drop(\"closed_at\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все удалилось, а нужные нам столбцы остались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим новый признак который бы показывал какое количество дней прошло между созданием стартапа и получения первого финансирования - first money**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"first_money\"] = (\n",
    "    df_ks_train[\"first_funding_at\"] - df_ks_train[\"founded_at\"]\n",
    ").dt.days\n",
    "df_ks_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим новый признак который бы показывал как часто финансироался стартам, для этого разницу между 1 и последним раундом финансирования разделим на количество раундов финансирования - frequency_financing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"frequency_financing\"] = (\n",
    "    (df_ks_train[\"last_funding_at\"] - df_ks_train[\"first_funding_at\"]).dt.days\n",
    ") / df_ks_train[\"funding_rounds\"]\n",
    "df_ks_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак у нас дополнительно создано 3 синтетических признака, которые должны помочь в обучении модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим визуализации изменения количества раундов финансирования компаний в зависимости от даты их основания**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series):\n",
    "    xs = series[\"founded_at\"]\n",
    "    ys = series[\"funding_rounds\"]\n",
    "    plt.plot(xs, ys)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5.2), layout=\"constrained\")\n",
    "df_sorted = df_ks_train.sort_values(\"founded_at\", ascending=True)\n",
    "plot_series(df_sorted)\n",
    "sns.despine(fig=fig, ax=ax)\n",
    "plt.xlabel(\"Дата основания компании\")\n",
    "plt.ylabel(\"Раунд финансирования\")\n",
    "plt.title(\"зависимость количества раундов финансирования от даты основания компаний\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный график может сказать, что компании в основном имеют до 7 раундов финансирования, а большая часть финансирования началась для компаний созданных после 2000 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_train[\"lifetime\"].plot(\n",
    "    kind=\"hist\", bins=50, title=\"Гистограмма времени жизни стартапа\"\n",
    ")\n",
    "plt.xlabel(\"Время жизни стартапа\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из данной гистограммы видим что время жизни стартапа в основном составляет около 2000 дней, что достаточно много, так же наблюдаются стартапы долгожители более 10 000 дней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Проведем корреляционный анализ данных, проверив данные на мультиколлинеарность**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем библиотеку FINK, но исключим данные связанные датами, такими как дата основания, первый и последний раунд финансирования. Основна временная позиция - это время жизни стартапа, думаю это будет основа нашего будущего предсказания.   \n",
    "*P.S. Если использовать все данные в таблице, расчет проводиться очень долго, поэтому оставлю для примера код страны и штата чтоб обозначить их сильную связь.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    df_ks_train.drop(\n",
    "        [\n",
    "            \"name\",\n",
    "            \"state_code\",\n",
    "            \"country_code\",\n",
    "            \"city\",\n",
    "            \"founded_at\",\n",
    "            \"first_funding_at\",\n",
    "            \"last_funding_at\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).phik_matrix(verbose=False),\n",
    "    annot=True,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cmap=\"coolwarm\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Коэффициент корреляции $\\phi_K$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшую взаимосвязь видим между целевым признаком количеством дней жизни стартапа - 0,54.\n",
    "\n",
    "Так же имеется достаточно сильная взаимосвязь между категорией и регионом - 0,74, временем жизни стартапа и количеством дней до первой даты финансирования - 0,88\n",
    "\n",
    "При мультиколлинеральноси имеются взаимосвязи т 0.9 до 0.95 по модулю. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор финального набора обучающих признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- status  - целевой признак\n",
    "- category_list - категория\n",
    "- funding_total_usd - объем финансирования\n",
    "- country_code - код страны\n",
    "- funding_rounds - раунд финансирования\n",
    "- lifetime - время жизни стартапа\n",
    "- first_money - получение первого финансирования\n",
    "- frequency_financing  - частота получения финансирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [\n",
    "    \"name\",\n",
    "    \"status\",\n",
    "    \"category_list\",\n",
    "    \"funding_total_usd\",\n",
    "    \"country_code\",\n",
    "    \"funding_rounds\",\n",
    "    \"lifetime\",\n",
    "    \"first_money\",\n",
    "    \"frequency_financing\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датафрейм содержащий только данные столбцы для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ks_train[feature]\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся что у нас не осталось пропусков в значениях необходимых для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведение аналогичной предобработки данных на тестовых (приведение к одному виду и размерности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(df_ks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts_test = df_ks_test.isna().sum()\n",
    "nan_counts_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются пропуски в используемых для обучения аналогичных колонках \n",
    "- category_list         591\n",
    "- funding_total_usd    2578\n",
    "- country_code         1382  \n",
    "\n",
    "Так как строки удалять нельзя (заполним пропуски)\n",
    "\n",
    "- category_list       - первым значением по категориям, остальные категорией Unknown\n",
    "- funding_total_usd    - медианным значением по категории\n",
    "- country_code         - категорией Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_test.loc[:, \"category_list\"] = df_ks_test[\"category_list\"].str.split(\"|\").str[0]\n",
    "df_ks_test[\"category_list\"] = df_ks_test[\"category_list\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции fill_with_median к каждой группе в столбце 'category_list'\n",
    "df_ks_test[\"funding_total_usd\"] = df_ks_test.groupby(\"category_list\")[\n",
    "    \"funding_total_usd\"\n",
    "].transform(lambda x: fill_with_median(x, x.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем NaN на 'Unknown'\n",
    "df_ks_test[\"country_code\"] = df_ks_test[\"country_code\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Создаем новые синтетические признаки из имеющихся, аналогичные тренировочному датасету**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks_test[\"first_money\"] = (\n",
    "    df_ks_test[\"first_funding_at\"] - df_ks_test[\"founded_at\"]\n",
    ").dt.days\n",
    "df_ks_test[\"frequency_financing\"] = (\n",
    "    (df_ks_test[\"last_funding_at\"] - df_ks_test[\"first_funding_at\"]).dt.days\n",
    ") / df_ks_test[\"funding_rounds\"]\n",
    "df_ks_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поддержания размерности оставить в тестовом датфрейме только столбцы аналогичные тренировочному (за исключением статус - его мы предсказываем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test = [\n",
    "    \"name\",\n",
    "    \"category_list\",\n",
    "    \"funding_total_usd\",\n",
    "    \"country_code\",\n",
    "    \"funding_rounds\",\n",
    "    \"lifetime\",\n",
    "    \"first_money\",\n",
    "    \"frequency_financing\",\n",
    "]\n",
    "df_test = df_ks_test[feature_test]\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размерость тествого и тренировочно, разница должна быть в один столбец (статус еще не создан в тестовом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.shape)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор и обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как данные несбалансированы, используем stratify=y, обеспечивая, что каждая выборка будет иметь представительное распределение классов, позволяя модели обучаться и тестироваться на данных, которые лучше отражают реальное распределение классов в исходном наборе данных. Это помогает улучшить надежность и обобщаемость модели машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фичи для обучения\n",
    "X = df_train.drop([\"name\", \"status\"], axis=1)\n",
    "y = df_train[\"status\"]  # Метки классов\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"category_list\", \"country_code\"]\n",
    "numeric_features = df_train.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем Pipeline для обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПЕРЕБОР МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим препроцессор - предварительный обработчик данных с помощью ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False),\n",
    "            categorical_features,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим итоговый пайплайн куда будем передавать предобработчик и модели с разными параметрами\n",
    "pipe_final = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"models\", DecisionTreeClassifier(random_state=42)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = [\n",
    "    # словарь для модели HistGradientBoostingClassifier\n",
    "    {\n",
    "        \"models\": [HistGradientBoostingClassifier()],\n",
    "        \"models__max_iter\": range(100, 150),\n",
    "        \"models__learning_rate\": [0.001, 0.01, 0.05, 0.1],\n",
    "        \"models__max_depth\": range(3, 5),\n",
    "        \"preprocessor__num\": [StandardScaler(), MinMaxScaler(), \"passthrough\"],\n",
    "    },\n",
    "    # словарь для модели DecisionTreeClassifier()\n",
    "    {\n",
    "        \"models\": [DecisionTreeClassifier(random_state=42)],\n",
    "        \"models__max_depth\": range(2, 6),\n",
    "        \"models__max_features\": range(2, 6),\n",
    "        \"preprocessor__num\": [StandardScaler(), MinMaxScaler(), \"passthrough\"],\n",
    "    },\n",
    "    # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        \"models\": [\n",
    "            LogisticRegression(random_state=42, solver=\"liblinear\", penalty=\"l1\")\n",
    "        ],\n",
    "        \"models__C\": range(1, 10),\n",
    "        \"preprocessor__num\": [StandardScaler(), MinMaxScaler(), \"passthrough\"],\n",
    "    },\n",
    "    # словарь для модели GradientBoostingClassifier\n",
    "    {\n",
    "        \"models\": [GradientBoostingClassifier(random_state=42)],\n",
    "        \"models__n_estimators\": (50, 150),\n",
    "        \"models__learning_rate\": (0.1, 1),\n",
    "        \"models__max_depth\": (3, 6),\n",
    "        \"models__min_samples_split\": (2, 4),\n",
    "        \"models__min_samples_leaf\": (1, 3),\n",
    "        \"preprocessor__num\": [StandardScaler(), MinMaxScaler(), \"passthrough\"],\n",
    "    },\n",
    "    # словарь для модели CatBoostClassifier\n",
    "    {\n",
    "        \"models\": [CatBoostClassifier(random_state=42, silent=True)],\n",
    "        \"models__depth\": range(2, 6),\n",
    "        \"models__learning_rate\": [0.03, 0.1, 0.3],\n",
    "        \"models__iterations\": [100, 200, 300],\n",
    "        \"preprocessor__num\": [StandardScaler(), MinMaxScaler(), \"passthrough\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search = RandomizedSearchCV(\n",
    "    pipe_final,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"f1_weighted\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем лучшую найденную модель для предсказания\n",
    "preds = randomized_search.predict(X_test)\n",
    "f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "print(f\"Метрика F1 на тестовой выборке: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Лучшая модель и её параметры:\")\n",
    "display(randomized_search.best_estimator_)\n",
    "print(\"Лучшие параметры модели:\", randomized_search.best_params_)\n",
    "print(\"Метрика лучшей модели на тренировочной выборке:\", randomized_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(randomized_search.cv_results_)[\n",
    "    [\"params\", \"std_test_score\", \"rank_test_score\", \"param_models\", \"mean_test_score\"]\n",
    "].sort_values(\"rank_test_score\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = (\n",
    "    randomized_search.best_estimator_\n",
    ")  # вот это лучшая модель (preprocessor + estimator), уже обученая.\n",
    "regressor = best_model.named_steps[\"models\"]  # Это отдельно модель\n",
    "preprocessor = best_model.named_steps[\"preprocessor\"]  # Это препроцессор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим адекватность модели с помощью Dummy модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_pred = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DummyClassifier F1 Score:\", f1_score(y_test, dummy_pred, average=\"weighted\"))\n",
    "print(\"Лучшая модель дает -  F1 Score:\", f1_score(y_test, preds, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты показывают, что наша модель имеет F1-меру 0.988, что значительно выше, чем F1-мера DummyClassifier, равная 0.861. Это указывает на то, что CatBoostClassifier работает лучше, чем простой классификатор, который делает предсказания, основываясь только на самом распространенном классе.\n",
    "\n",
    "F1-мера является гармоническим средним между точностью и полнотой, и она особенно полезна, когда распределение классов несбалансировано.     \n",
    "Высокое значение F1-меры для CatBoostClassifier говорит о том, что модель хорошо справляется с балансом между точностью и полнотой, что делает ее адекватной для нашей задачи классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocessor.get_feature_names_out(input_features=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = regressor.feature_importances_\n",
    "# Сортировка признаков по важности\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Вывод и визуализация ТОП 10 важности признаков\n",
    "top_features = np.array(feature_names)[sorted_idx][:10]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"ТОП 10 важности признаков\")\n",
    "plt.barh(top_features, feature_importance[sorted_idx][:10], align=\"center\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение важности признаков с помощью библиотеки SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация объекта SHAP Explainer\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "# Вычисление SHAP значений для тестового набора данных\n",
    "shap_values = explainer.shap_values(preprocessor.transform(X_test))\n",
    "# Визуализация важности признаков\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    preprocessor.transform(X_test),\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    max_display=10,\n",
    "    plot_size=(8, 6),\n",
    "    title=\"Важность признаков\",\n",
    "    show=False,\n",
    ")\n",
    "plt.title(\"Важность признаков\", fontsize=12)\n",
    "plt.xlabel(\"SHAP значение\", fontsize=10)\n",
    "plt.ylabel(\"Признаки\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(df_test)\n",
    "len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"status\"] = y_test_pred\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resuilt_pred_2 = df_test.loc[:, [\"name\", \"status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resuilt_pred_2.to_csv(\"./pred_output/pred_data_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
